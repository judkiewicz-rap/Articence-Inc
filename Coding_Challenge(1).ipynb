{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coding Challenge.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87d2cadd55af4c92a3a8dfcdf64f7ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93a6f7eccce44f0cbecb87c08151d341",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ff47938ba554a35b215a717190b9504",
              "IPY_MODEL_700420b2997c4779a6aa7b9148256d03"
            ]
          }
        },
        "93a6f7eccce44f0cbecb87c08151d341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ff47938ba554a35b215a717190b9504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_773fb9aa70db447bada6510d7e17af2b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc7228b3bb0749ee922fcefc3acb1d06"
          }
        },
        "700420b2997c4779a6aa7b9148256d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc22ec8fc3824c5fb509fec8659817c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 1.26MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ccb41ef72984feaae26b507354eee69"
          }
        },
        "773fb9aa70db447bada6510d7e17af2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc7228b3bb0749ee922fcefc3acb1d06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc22ec8fc3824c5fb509fec8659817c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ccb41ef72984feaae26b507354eee69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d3214a6a6344813a4129aefd17ccfe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7364f47bc1a45138c1cbf223770b31c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_81048a8453f24ac5ae3ffd883985b9c6",
              "IPY_MODEL_5d184b18e9d745a296fed653ed11beb4"
            ]
          }
        },
        "c7364f47bc1a45138c1cbf223770b31c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81048a8453f24ac5ae3ffd883985b9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_976bb40f1dfd4ae29ea9b49bdfd09728",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c12bfcafb03450c9cdbabc30b23f05c"
          }
        },
        "5d184b18e9d745a296fed653ed11beb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2a1128c395b24eb2bc394a48c8d57125",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.37kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3ddd048e2094e8da0448f981179ab14"
          }
        },
        "976bb40f1dfd4ae29ea9b49bdfd09728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c12bfcafb03450c9cdbabc30b23f05c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a1128c395b24eb2bc394a48c8d57125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3ddd048e2094e8da0448f981179ab14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c30408a36e84799adc2ecbfae77128d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d447af8da4404cbd9510b1b53425fa5b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26233dc2ac3243ad9d1d7e172e5ebf78",
              "IPY_MODEL_55c6ad360dca438fa5db42d0a559f75b"
            ]
          }
        },
        "d447af8da4404cbd9510b1b53425fa5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26233dc2ac3243ad9d1d7e172e5ebf78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_46f8815232d647eba741ef56895d348d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c55e5ef3efd43a4a1bd04abd0e6d1e2"
          }
        },
        "55c6ad360dca438fa5db42d0a559f75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5418f9b6d8f43f7a5034a1868da8241",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:13&lt;00:00, 32.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfac505dc4154fa780fa232b03c44962"
          }
        },
        "46f8815232d647eba741ef56895d348d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c55e5ef3efd43a4a1bd04abd0e6d1e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5418f9b6d8f43f7a5034a1868da8241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfac505dc4154fa780fa232b03c44962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPx4a6tHZ1UL",
        "colab_type": "code",
        "outputId": "dc94ca64-a42b-4f5f-8714-0bb46da1ced7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 14.9MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 14.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 23.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 26.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=fcbe0308a8018ea2cf73ebf1f7c4f7906fe8e86af97256f09e2b3fa86c1a1355\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR0l7IPGpoWX",
        "colab_type": "code",
        "outputId": "85410231-479a-45ab-946b-8b515caf87fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "pip install emoji"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=f2be6ba38e741f51ed8a70665c93d0c76f8bd088392ee0e6698f4565fa5738f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHn0UV9OhoPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers as ppb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, optim\n",
        "import gensim.summarization\n",
        "import emoji"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYtYgQGxTejM",
        "colab_type": "code",
        "outputId": "f20dbafe-2cfd-446f-d773-de643a301e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1bFYRBWjAqXFxrRnA6XGqRY2ffh6gsAgG'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('IMDB Dataset.csv') \n",
        "data = pd.read_csv('IMDB Dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>length of text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Match 1: Tag Team Table Match Bubba Ray and Sp...</td>\n",
              "      <td>13704</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>There's a sign on The Lost Highway that says:&lt;...</td>\n",
              "      <td>12988</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Some spoilers included:)&lt;br /&gt;&lt;br /&gt;Although,...</td>\n",
              "      <td>12930</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Back in the mid/late 80s, an OAV anime by titl...</td>\n",
              "      <td>12129</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>**Attention Spoilers**&lt;br /&gt;&lt;br /&gt;First of all...</td>\n",
              "      <td>10363</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  length of text sentiment\n",
              "0  Match 1: Tag Team Table Match Bubba Ray and Sp...           13704  positive\n",
              "1  There's a sign on The Lost Highway that says:<...           12988  positive\n",
              "2  (Some spoilers included:)<br /><br />Although,...           12930  positive\n",
              "3  Back in the mid/late 80s, an OAV anime by titl...           12129  positive\n",
              "4  **Attention Spoilers**<br /><br />First of all...           10363  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omeiGCiNRJoA",
        "colab_type": "code",
        "outputId": "ae4c86bc-383d-491c-8ff8-f9f8f917bb30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haOJdJmmU1PT",
        "colab_type": "code",
        "outputId": "dde2de87-ff6f-46a7-9459-ecda860f9392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "data['sentiment'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96He1_Fh6ir8",
        "colab_type": "text"
      },
      "source": [
        "We're gona tranform the sentiment into a dummy variable so the analysis will be easier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d99Gw0WPt-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['sentiment']=data['sentiment'].apply(lambda row: np.where(row=='positive',1,0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T3gcjGMQByt",
        "colab_type": "code",
        "outputId": "51abfac3-8ce5-48f6-c958-425a1cdc8df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "data['sentiment'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    25000\n",
              "0    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb5r3jMBU9wC",
        "colab_type": "text"
      },
      "source": [
        "The dataset is balanced, we don't need to modify it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFGWD_giGPcZ",
        "colab_type": "text"
      },
      "source": [
        "Let's analyze the distribution of the lenght of the reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXh1GKIaGZr6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "08aa0be0-8538-4141-ad80-73218655fe6b"
      },
      "source": [
        "data['length of text'].hist(bins=25)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5b92ee6be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm3w_70XRAA-",
        "colab_type": "text"
      },
      "source": [
        "We can see that most of the review lengths are between 500 and 2000. We will keep that in mind for later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vql-jVaK_VuL",
        "colab_type": "text"
      },
      "source": [
        "The Bert tokenizer that we will use after does not recognize emoji, it encodes them with an unknown token. Therefore, we should transform each smiley in the reviews into text. To do that, we will use the emoji librairy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcHHa-9D_tU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emoji_2_text(review):\n",
        "    return emoji.demojize(review)\n",
        "data['review']=data['review'].apply(lambda x:emoji_2_text(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_melE-RR_9WH",
        "colab_type": "text"
      },
      "source": [
        "We then split it so that we can cross-validate our resutls."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXjJ6JkH7eCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_test = train_test_split(data, test_size=0.1)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOoK1PD7mySw",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizing the reviews with the first 200 tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9esCr2QB63pt",
        "colab_type": "text"
      },
      "source": [
        "We need to preprocess the data by tokenizing it, so that it can bu understood by our model. To do that, we're gonna use the pre-trained Bert Tranformer from the transformer librairy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn3uqudVm_CA",
        "colab_type": "text"
      },
      "source": [
        "The max length is the length of the tokenizez sentence. Normally, Bert accept a max length of 512. However, because of memory issues, we are only using 200.\n",
        "To begin with, we will only use the first 200 hundred tokens, because it seeems logical that the beginning of the review gives the tone of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZnsfJkhddzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AJivPmS7pt1",
        "colab_type": "text"
      },
      "source": [
        "After that, we need to create a Data Loader to use the resulting dataset of our pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfd1srWICpsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df['review'].to_numpy(),\n",
        "    targets=df['sentiment'].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chKBr4ZwO6kQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "87d2cadd55af4c92a3a8dfcdf64f7ac2",
            "93a6f7eccce44f0cbecb87c08151d341",
            "3ff47938ba554a35b215a717190b9504",
            "700420b2997c4779a6aa7b9148256d03",
            "773fb9aa70db447bada6510d7e17af2b",
            "fc7228b3bb0749ee922fcefc3acb1d06",
            "cc22ec8fc3824c5fb509fec8659817c6",
            "5ccb41ef72984feaae26b507354eee69"
          ]
        },
        "outputId": "b5c2ae96-86d7-4047-a9f3-001890a4f0ca"
      },
      "source": [
        "tokenizer = ppb.BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87d2cadd55af4c92a3a8dfcdf64f7ac2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tM6sKnUD2Fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "max_len=200\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, max_len, batch_size)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, max_len, batch_size)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, max_len, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VNpOh-281pS",
        "colab_type": "text"
      },
      "source": [
        "Bert is already pre-trained, thus we can use transfer learning so get some results. In this case, we're adding a dropout layer, and a fully-connected with two neurons for our output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dCpn5ZoC5yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = ppb.BertModel.from_pretrained('bert-base-cased')\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEPkr7EOM9Kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg0vbNJpC6_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "7d3214a6a6344813a4129aefd17ccfe6",
            "c7364f47bc1a45138c1cbf223770b31c",
            "81048a8453f24ac5ae3ffd883985b9c6",
            "5d184b18e9d745a296fed653ed11beb4",
            "976bb40f1dfd4ae29ea9b49bdfd09728",
            "3c12bfcafb03450c9cdbabc30b23f05c",
            "2a1128c395b24eb2bc394a48c8d57125",
            "d3ddd048e2094e8da0448f981179ab14",
            "1c30408a36e84799adc2ecbfae77128d",
            "d447af8da4404cbd9510b1b53425fa5b",
            "26233dc2ac3243ad9d1d7e172e5ebf78",
            "55c6ad360dca438fa5db42d0a559f75b",
            "46f8815232d647eba741ef56895d348d",
            "7c55e5ef3efd43a4a1bd04abd0e6d1e2",
            "f5418f9b6d8f43f7a5034a1868da8241",
            "cfac505dc4154fa780fa232b03c44962"
          ]
        },
        "outputId": "95626547-ee3e-4bb8-b541-6ccc7fc94880"
      },
      "source": [
        "model = SentimentClassifier(2)\n",
        "model = model.to(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d3214a6a6344813a4129aefd17ccfe6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c30408a36e84799adc2ecbfae77128d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ondbXvP39awG",
        "colab_type": "text"
      },
      "source": [
        "We're gonna try our model on a test batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC6iwj5eQUGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = next(iter(train_data_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKkj4TukMqmR",
        "colab_type": "code",
        "outputId": "da0a6ceb-3f2d-4b84-e21c-5a6f6598d087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "input_ids = test['input_ids'].to(device)\n",
        "attention_mask = test['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 190])\n",
            "torch.Size([32, 190])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrsF3VpRDS8H",
        "colab_type": "code",
        "outputId": "15cb35cc-6ed1-4090-c741-e4ca85877eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "nn.functional.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3329, 0.6671],\n",
              "        [0.4183, 0.5817],\n",
              "        [0.4476, 0.5524],\n",
              "        [0.4181, 0.5819],\n",
              "        [0.3227, 0.6773],\n",
              "        [0.3827, 0.6173],\n",
              "        [0.4774, 0.5226],\n",
              "        [0.4149, 0.5851],\n",
              "        [0.4016, 0.5984],\n",
              "        [0.2502, 0.7498],\n",
              "        [0.3218, 0.6782],\n",
              "        [0.4558, 0.5442],\n",
              "        [0.3248, 0.6752],\n",
              "        [0.4646, 0.5354],\n",
              "        [0.3817, 0.6183],\n",
              "        [0.4822, 0.5178],\n",
              "        [0.5556, 0.4444],\n",
              "        [0.4348, 0.5652],\n",
              "        [0.4572, 0.5428],\n",
              "        [0.4661, 0.5339],\n",
              "        [0.3521, 0.6479],\n",
              "        [0.2482, 0.7518],\n",
              "        [0.3468, 0.6532],\n",
              "        [0.4242, 0.5758],\n",
              "        [0.3519, 0.6481],\n",
              "        [0.4405, 0.5595],\n",
              "        [0.3864, 0.6136],\n",
              "        [0.4986, 0.5014],\n",
              "        [0.3832, 0.6168],\n",
              "        [0.4369, 0.5631],\n",
              "        [0.5234, 0.4766],\n",
              "        [0.4387, 0.5613]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7vd8kegQVz9",
        "colab_type": "code",
        "outputId": "44a7c673-42bf-469f-c928-e40532b80157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "test['targets']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "        0, 0, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQEsHPQk9X2P",
        "colab_type": "text"
      },
      "source": [
        "We can see that on a batch test, the results seem coherent. We will now try to train the pre-trained model, to get the best results possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMZkKfOwDTiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "optimizer = ppb.AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = ppb.get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYteMQNuDWMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt7lbRkQD71v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYKzsyk7D9n8",
        "colab_type": "code",
        "outputId": "8a8bc40b-b74d-44c8-cad4-c6618c2e8080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "----------\n",
            "Train loss 0.2783853772844968 accuracy 0.8827555555555556\n",
            "Val   loss 0.24300923085288156 accuracy 0.9012\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "Train loss 0.14202730469180597 accuracy 0.9499333333333334\n",
            "Val   loss 0.2819033622553077 accuracy 0.9088\n",
            "\n",
            "CPU times: user 56min 20s, sys: 35min 21s, total: 1h 31min 42s\n",
            "Wall time: 1h 32min 20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwzaeTNC9uj5",
        "colab_type": "text"
      },
      "source": [
        "The results are actually pretty good on the train and the validation set. Let's see the performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3q67Z0JQtLW",
        "colab_type": "code",
        "outputId": "7fd921ff-8baf-49f0-dd04-d4d35ccba68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6WKWKNB-AHj",
        "colab_type": "text"
      },
      "source": [
        "The accuracy on the test set is almost the same, we don't have an overfitting problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huFrraY1-EQu",
        "colab_type": "text"
      },
      "source": [
        "If we wanted to imporve our model, we should firstly set the max_length at 512. However, most of the sentences are longer that that. therefore, we could separate the reviews into parts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8DUBBQF4jzO",
        "colab_type": "text"
      },
      "source": [
        "# Aternate way of tokenizing the reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LnhOaEuANbC",
        "colab_type": "text"
      },
      "source": [
        "The previous solution was not optimal because we only used 200 hundred tokens, and therefore, we lost some information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn7stfLK4q3B",
        "colab_type": "text"
      },
      "source": [
        "My first idea was to separate the reviews into parts of length 200 each, and then feed them into Bert, and then use a layer such as max pooling, or even a LSTM layer to concatenate the results. However, by looking into some research papers, I found a paper, *How to Fine-Tune BERT for Text Classification?* (https://arxiv.org/pdf/1905.05583.pdf), which shows that this is not the most efficient method. Instead, we should take the head and the tail of the review, in order to get the most important information, and that is what I am going to do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9BV3PG-FfeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def select(review):\n",
        "    if len(review)<=200: return review\n",
        "    else:\n",
        "        return review[:99]+' '+review[-98:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYEoiYmcFgei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "34c0460e-b0ae-4a9c-f3b2-741693312c92"
      },
      "source": [
        "df_train['review']=df_train['review'].apply(lambda x:select(x))\n",
        "df_val['review']=df_val['review'].apply(lambda x:select(x))\n",
        "df_test['review']=df_test['review'].apply(lambda x:select(x))\n",
        "len(df_train['review'].iloc[0])   #we should fing a length of 198, because the tokenizer is going to add 2 tokens, the [CLS] token and the [SEP] token"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cK2xZqfGPpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "max_len=200\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, max_len, batch_size)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, max_len, batch_size)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, max_len, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZpyAdYxGVWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = SentimentClassifier(2)\n",
        "model2 = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxUO2k5ctn6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "optimizer = ppb.AdamW(model2.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = ppb.get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRqb9YSiGaD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "12f12b73-8490-47d4-eed9-88b4461a4ca6"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model2,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model2,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "----------\n",
            "Train loss 0.35626622754881887 accuracy 0.8368888888888889\n",
            "Val   loss 0.277257391546346 accuracy 0.8748\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "Train loss 0.18735043215217875 accuracy 0.9262\n",
            "Val   loss 0.32782580538452427 accuracy 0.8712000000000001\n",
            "\n",
            "CPU times: user 55min 29s, sys: 33min 29s, total: 1h 28min 59s\n",
            "Wall time: 1h 29min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0FOL-dFGgQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "434e4758-3038-4e30-b9fe-7f55532661a7"
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model2,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5kp6YyzCxeM",
        "colab_type": "text"
      },
      "source": [
        "The accuracy on the test dataset is a bit lower than the previous model, but this may be because we only trained on 2 epochs. We should try to learn on 10 epochs to really analyze the results. However, for now, we will consider that the first model is better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDsstsHU8Z-C",
        "colab_type": "text"
      },
      "source": [
        "# Summarizing each reviews into a summary of length 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ8gdcjz8h_6",
        "colab_type": "text"
      },
      "source": [
        "We are still confronted to the problem of taking only 200 tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHFpJ1Ef8o07",
        "colab_type": "text"
      },
      "source": [
        "To solve this issue, we can try to summaryze each reviews into a summary of length 200, and then apply our sentiment analysis model. To summaryze the reviews, we are going to use gensim, a library in python. It may solve our problem, because the summary should contain the most important information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsJnfQyV89qE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summary(review, word_count):\n",
        "    if len(review)<=200: return review\n",
        "    elif len(gensim.summarization.textcleaner.clean_text_by_sentences(review))==1:  #if there is only one sentence, gensim.summerize raise a value error. To solve this we are making sure that there are mor tham one sentence.\n",
        "        return review[:99]+' '+review[-98:]                               # If there is only one sentence we take the beginning and the end of the review as our summary.\n",
        "    elif len(gensim.summarization.summarize(review, word_count=word_count))==0:\n",
        "        return review[:99]+' '+review[-98:]\n",
        "    else:\n",
        "        return gensim.summarization.summarize(review, word_count=word_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O037GGvbnqa",
        "colab_type": "text"
      },
      "source": [
        "We will choose a summary of approximately 45 words, because a word is 5 characters long in average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSuE7Fi-RWyw",
        "colab_type": "code",
        "outputId": "123375f6-5989-4db3-eafc-4606fea3903c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "df_train['summary']=df_train['review'].apply(lambda r:summary(r.replace('.','. ').replace('<br /><br />','. '), word_count=45))\n",
        "df_val['summary']=df_val['review'].apply(lambda r:summary(r.replace('.','. ').replace('<br /><br />','. '), word_count=45))\n",
        "df_test['summary']=df_test['review'].apply(lambda r:summary(r.replace('.','. ').replace('<br /><br />','. '), word_count=45))\n",
        "df_train.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>length of text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35988</th>\n",
              "      <td>this is a really great series. i love the show...</td>\n",
              "      <td>722</td>\n",
              "      <td>1</td>\n",
              "      <td>it has really good humor and shows the realist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25712</th>\n",
              "      <td>Once again John Madden has given us a magnific...</td>\n",
              "      <td>950</td>\n",
              "      <td>1</td>\n",
              "      <td>Anyway, Cage was very good in one of his best ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13190</th>\n",
              "      <td>Fame, I think, was the best movie that I have ...</td>\n",
              "      <td>1538</td>\n",
              "      <td>1</td>\n",
              "      <td>In ways it was funny and dramatic, but that is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48898</th>\n",
              "      <td>Hilarious, Sellers at his funniest ... a shame...</td>\n",
              "      <td>270</td>\n",
              "      <td>1</td>\n",
              "      <td>Hilarious, Sellers at his funniest .\\na shame ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30067</th>\n",
              "      <td>I happened to catch this on TV, and wanted to ...</td>\n",
              "      <td>836</td>\n",
              "      <td>0</td>\n",
              "      <td>First, if James Belushi is the lead actor in a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  ...                                            summary\n",
              "35988  this is a really great series. i love the show...  ...  it has really good humor and shows the realist...\n",
              "25712  Once again John Madden has given us a magnific...  ...  Anyway, Cage was very good in one of his best ...\n",
              "13190  Fame, I think, was the best movie that I have ...  ...  In ways it was funny and dramatic, but that is...\n",
              "48898  Hilarious, Sellers at his funniest ... a shame...  ...  Hilarious, Sellers at his funniest .\\na shame ...\n",
              "30067  I happened to catch this on TV, and wanted to ...  ...  First, if James Belushi is the lead actor in a...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYTNiWy1VCZV",
        "colab_type": "text"
      },
      "source": [
        "We now have two change our dataset class, and our dataloader in order to use the summaries instead of the reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IO1ZDvIU7Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, summaries, targets, tokenizer, max_len):\n",
        "    self.summaries = summaries\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.summaries)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    summary = str(self.summaries[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      summary,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_LrtTvVcnFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    summaries=df['summary'].to_numpy(),\n",
        "    targets=df['sentiment'].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkeuWvCrdP2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "max_len=200\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, max_len, batch_size)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, max_len, batch_size)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, max_len, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "281_NTlMeD7V",
        "colab_type": "text"
      },
      "source": [
        "We keep the same functions, we just change the data loader. Thus, we can now easily train the data on the summaries instead of the reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzedUs96VXUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_sum = SentimentClassifier(2)\n",
        "model_sum = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuQCjiMDttJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "optimizer = ppb.AdamW(model_sum.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = ppb.get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXSFVnD5dT9W",
        "colab_type": "code",
        "outputId": "a7fd53f6-6f5a-4d8b-a90c-11c1b0600317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model_sum,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model_sum,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "----------\n",
            "Train loss 0.41706442546467454 accuracy 0.8433333333333334\n",
            "Val   loss 0.5001490199113194 accuracy 0.8260000000000001\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "Train loss 0.41551492499040643 accuracy 0.8434\n",
            "Val   loss 0.5001490199113194 accuracy 0.8260000000000001\n",
            "\n",
            "CPU times: user 55min 11s, sys: 34min 40s, total: 1h 29min 52s\n",
            "Wall time: 1h 30min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkmN3qrSs7KD",
        "colab_type": "code",
        "outputId": "80b30261-97f7-4a41-e281-917a25d64390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model_sum,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6lP3r_TzfZJ",
        "colab_type": "text"
      },
      "source": [
        "The accuray is a bit lower than the previous model. One of the explanantion could be that the first words contains the sentiment of the reviews and may not be contained in the summary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cad5xlMSSs7",
        "colab_type": "text"
      },
      "source": [
        "# Real data inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVQ-Xv9uVhkR",
        "colab_type": "text"
      },
      "source": [
        "In order to try the best model with real life data, I went on the IMDB website and I selected 2 good reviews and 2 bad reviews for three movies: Jurassic World, Inception and Uncut Gems. Let's see how the model works with this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bocZWKuiSmql",
        "colab_type": "text"
      },
      "source": [
        "We will try it with our first model, which has the best accuracy on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Ys8i6pSVBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review1=\"Is a solid movie and it holds itself as a trilling experience for everyone. Yes, people from the original cast are not there, however there is actually not a logical reason in the time line to make them go back. Taking out this little detail, the acting is amazing and Chris Pratt holds amazingly as a main character again . Animations are better than ever and the story line even if a little prematurely developed is exciting and looks to reward the new audience as well as the hard on fans. Overall is a great movie which promise enjoyment. I loved it and I will recommend it for everyone that is a fan and for the ones that just want to see a movie that will print a smile at the end.\"\n",
        "review2=\"Of course it isn't powerful like the first one, but a super great movie.\"\n",
        "review3=\"Everything about this movie is top notch. The cast, directing, and plot all breed depth and endless layers of complexity.\"\n",
        "review4=\"An impressive detail seen elsewhere.If you pull out the first letters of the main characters' names (Dom, Robert, Eames, Arther, Mal, Saito), they make up the word 'dreams'.Then I found out that the movie was really full of secrets.\"\n",
        "review5=\"The fact that this film didn't even get any Oscar nominations is a crime. It's a crazy, anxiety-inducing roller coaster ride, and the rewatchability is insane.\"\n",
        "review6=\"I dont know where the cliche over played Adam Sandler came up with this acting but.... much respect to him for a great portrayl of his character.. This movie is amazing and deserves to be watched and rewatched.. If you gamble or enjoy the idea of a risk taker in financial means.. you will enjoy this soo much.. The only reason im writing is because woooww finally Adam. S actually did the job I wished he could do in all of his movies, he went out of his comfort zone in this and it shows. Much respect to him and the beautiful duo from Good Time that made this happen..\"\n",
        "review7=\"This movie sucked, it was horrible. It has the most confusing story and the original Jurassic park was so much better. I wish it was directed by somebody else because the person who directed this sucked at it. I'm lucky I didn't see this in theaters because I would've wasted my money. Please take my advice and don't watch it because the movie is boring and terrible.\"\n",
        "review8=\"Almost every idea of this movie 'Jurassic World'  is copied from its 1993 original Jurassic Park. Even the characters are the same: one male protagonist, one female protagonist, two children and some stupid guys. It is a shame that today filmmakers have lost their pioneering spirit and just rely on sequel, reboot or remake of existing intellectual properties for cash grab purposes.\"\n",
        "review9=\"I think all the other 1 star voters stated exactly how I feel about this movie. I have never felt motivated to write a movie review in my life. This was one of the worst movies I've ever seen! My favorite movie reviewer gave it 4/4 stars. I am baffled - - I really feel like I'm missing something... although there seem to be many out there that have the same thoughts I do. Thanks for confirming my opinions! I could tell within five minutes of the movie that I was not going to like it and that I wouldn't be able to follow it. Should have walked out then. I am the most sympathetic person to characters in a movie. I was amazed that I couldn't care less if all of the main characters were shot dead. There was zero character development. I felt a bit nauseous from all of the action and I really coudn't tell what was going on a lot of the time.\"\n",
        "review10=\"Frankly, I don't see how all these people vote for 8. Inception is such a claustrophobic and overwhelming movie. The whole movie is extremely boring and isn't containing any funny moment. Yes, we are all know that this is not a comic. But the movie is going so serious when there's nothing to be serious about.\"\n",
        "review11=\"This movie is a headache. I don't understand the constant, terrible background music.\"\n",
        "review12=\"This movie was brutal if there is one word to describe it. The score and music was horrible didn't match or go with the movie already making you not invested... from a terrible script that had some ideas but never latched onto anything but bad acting, screaming, and unwanted sex scenes that will make you cringe. An ending that attempted to save this disaster but was too little too late. Awful awful film that should have zero praise just because it is an indie pic.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrSzM4DaSXkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4d4905f3-d00c-4089-92cb-d0f932b15107"
      },
      "source": [
        "sentiment=[1,1,1,1,1,1,0,0,0,0,0,0]\n",
        "reviews=[review1,review2,review3,review4,review5,review6,review7,review8,review9,review10,review11,review12]\n",
        "df_real=pd.DataFrame({'review':reviews,'sentiment':sentiment})\n",
        "df_real.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is a solid movie and it holds itself as a tril...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Of course it isn't powerful like the first one...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Everything about this movie is top notch. The ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>An impressive detail seen elsewhere.If you pul...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The fact that this film didn't even get any Os...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  Is a solid movie and it holds itself as a tril...          1\n",
              "1  Of course it isn't powerful like the first one...          1\n",
              "2  Everything about this movie is top notch. The ...          1\n",
              "3  An impressive detail seen elsewhere.If you pul...          1\n",
              "4  The fact that this film didn't even get any Os...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EHa08OZSY_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_data_loader = create_data_loader(df_real, tokenizer, max_len, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc0k-pp8SvQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5eb389b-03ea-4e94-f5ca-5f4683bef7e6"
      },
      "source": [
        "real_acc, _ = eval_model(\n",
        "  model,\n",
        "  real_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_real)\n",
        ")\n",
        "\n",
        "real_acc.item()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB3toZULV3Zz",
        "colab_type": "text"
      },
      "source": [
        "The accuracy is one, which means that every review was correctly labelled. This shows that our model works great with real-world data. The perfect accuracy is due to the fact that I chose the best 2 reviews and the worst reviews for each movie, therefore, the reviews were unambiguously positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtYNHSIBWaib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}